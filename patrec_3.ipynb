{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "patrec-3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r5fugKba8Gk0",
        "larljHJk8Gk7",
        "DfCmoMns8GlA",
        "VoEmYX_G8GlD",
        "ITN7NfPW8Glb",
        "tpr0O5tUzspM",
        "xEYU6eETxFPF",
        "aIKuxL2Hqn6i",
        "SRkvKn4Uqn6y"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Αναγνώριση Προτύπων\n",
        "\n",
        "### 3η Εργαστηριακή Άσκηση\n",
        "### Αναγνώριση Είδους και Εξαγωγή Συναισθήματος από Μουσική\n",
        "\n",
        "Ακαρέπης Ανδρέας, 03117058\n",
        "\n",
        "Κόντη Πολυξένη Ειρήνη, 03117180"
      ],
      "metadata": {
        "id": "kQtUwHch8Gkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from scipy.stats import spearmanr\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:26:36.333697Z",
          "iopub.execute_input": "2022-02-27T14:26:36.333989Z",
          "iopub.status.idle": "2022-02-27T14:26:38.827683Z",
          "shell.execute_reply.started": "2022-02-27T14:26:36.333962Z",
          "shell.execute_reply": "2022-02-27T14:26:38.826938Z"
        },
        "trusted": true,
        "id": "7yg-KgF4qn6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"../input/patreco3-multitask-affective-music/data/\")"
      ],
      "metadata": {
        "id": "_0_uCU3o8Gkz",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:56.263403Z",
          "iopub.execute_input": "2022-02-26T19:57:56.263845Z",
          "iopub.status.idle": "2022-02-26T19:57:56.278090Z",
          "shell.execute_reply.started": "2022-02-26T19:57:56.263808Z",
          "shell.execute_reply": "2022-02-26T19:57:56.277041Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 1\n",
        "\n",
        "Επιλέγονται τα αρχεία '65784.beatsync.fused.npy.gz' και '80238.beatsync.fused.npy.gz' που ανήκουν στις κατηγορίες classical και blues αντίστοιχα"
      ],
      "metadata": {
        "id": "r5fugKba8Gk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#β\n",
        "specClassical = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/65784.fused.full.npy')\n",
        "specBlues = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/80238.fused.full.npy')"
      ],
      "metadata": {
        "id": "w4mVyPsZ8Gk1",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:56.280752Z",
          "iopub.execute_input": "2022-02-26T19:57:56.280934Z",
          "iopub.status.idle": "2022-02-26T19:57:56.393652Z",
          "shell.execute_reply.started": "2022-02-26T19:57:56.280912Z",
          "shell.execute_reply": "2022-02-26T19:57:56.392920Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(specClassical.shape)\n",
        "print(specBlues.shape)"
      ],
      "metadata": {
        "id": "5XFMeJfW8Gk2",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:56.395667Z",
          "iopub.execute_input": "2022-02-26T19:57:56.395925Z",
          "iopub.status.idle": "2022-02-26T19:57:56.400694Z",
          "shell.execute_reply.started": "2022-02-26T19:57:56.395892Z",
          "shell.execute_reply": "2022-02-26T19:57:56.400023Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melClassical, chromaClassical = specClassical[:128], specClassical[128:]\n",
        "melBlues, chromaBlues = specBlues[:128], specBlues[128:]"
      ],
      "metadata": {
        "id": "cNSRIoLY8Gk3",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:56.402043Z",
          "iopub.execute_input": "2022-02-26T19:57:56.402622Z",
          "iopub.status.idle": "2022-02-26T19:57:56.410092Z",
          "shell.execute_reply.started": "2022-02-26T19:57:56.402579Z",
          "shell.execute_reply": "2022-02-26T19:57:56.409351Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#γ\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(melClassical, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Spectrogram of a Classical type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(melBlues, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Spectrogram of an Blues type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
      ],
      "metadata": {
        "id": "FbzLjdDh8Gk5",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:56.411113Z",
          "iopub.execute_input": "2022-02-26T19:57:56.411399Z",
          "iopub.status.idle": "2022-02-26T19:57:57.668796Z",
          "shell.execute_reply.started": "2022-02-26T19:57:56.411364Z",
          "shell.execute_reply": "2022-02-26T19:57:57.668035Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 2"
      ],
      "metadata": {
        "id": "larljHJk8Gk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#α\n",
        "print(melClassical.shape)\n",
        "print(melBlues.shape)"
      ],
      "metadata": {
        "id": "bw82uK_28Gk8",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:57.670289Z",
          "iopub.execute_input": "2022-02-26T19:57:57.670526Z",
          "iopub.status.idle": "2022-02-26T19:57:57.675360Z",
          "shell.execute_reply.started": "2022-02-26T19:57:57.670496Z",
          "shell.execute_reply": "2022-02-26T19:57:57.674637Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#β\n",
        "specClassicalBeat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/65784.fused.full.npy')\n",
        "specBluesBeat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/80238.fused.full.npy')"
      ],
      "metadata": {
        "id": "hWoGeHHv8Gk9",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:57.676663Z",
          "iopub.execute_input": "2022-02-26T19:57:57.677240Z",
          "iopub.status.idle": "2022-02-26T19:57:57.697418Z",
          "shell.execute_reply.started": "2022-02-26T19:57:57.677183Z",
          "shell.execute_reply": "2022-02-26T19:57:57.696650Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(specClassicalBeat.shape)\n",
        "print(specBluesBeat.shape)"
      ],
      "metadata": {
        "id": "W4aw5ITV8Gk9",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:57.698518Z",
          "iopub.execute_input": "2022-02-26T19:57:57.698711Z",
          "iopub.status.idle": "2022-02-26T19:57:57.704308Z",
          "shell.execute_reply.started": "2022-02-26T19:57:57.698688Z",
          "shell.execute_reply": "2022-02-26T19:57:57.703496Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melClassicalBeat, chromaClassicalBeat = specClassicalBeat[:128], specClassicalBeat[128:]\n",
        "melBluesBeat, chromaBluesBeat = specBluesBeat[:128], specBluesBeat[128:]"
      ],
      "metadata": {
        "id": "NG4zwBHk8Gk-",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:57.708394Z",
          "iopub.execute_input": "2022-02-26T19:57:57.708973Z",
          "iopub.status.idle": "2022-02-26T19:57:57.713243Z",
          "shell.execute_reply.started": "2022-02-26T19:57:57.708938Z",
          "shell.execute_reply": "2022-02-26T19:57:57.712528Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(melClassicalBeat, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Spectrogram of a Classical type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(melBluesBeat, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Spectrogram of an Blues type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
      ],
      "metadata": {
        "id": "iFEq5h4U8Gk_",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:57.714687Z",
          "iopub.execute_input": "2022-02-26T19:57:57.715085Z",
          "iopub.status.idle": "2022-02-26T19:57:58.243733Z",
          "shell.execute_reply.started": "2022-02-26T19:57:57.715049Z",
          "shell.execute_reply": "2022-02-26T19:57:58.243029Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 3"
      ],
      "metadata": {
        "id": "DfCmoMns8GlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chromaClassical.shape)\n",
        "print(chromaBlues.shape)\n",
        "\n",
        "print(chromaClassicalBeat.shape)\n",
        "print(chromaBluesBeat.shape)"
      ],
      "metadata": {
        "id": "87KodTeW8GlA",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:58.246491Z",
          "iopub.execute_input": "2022-02-26T19:57:58.246679Z",
          "iopub.status.idle": "2022-02-26T19:57:58.253891Z",
          "shell.execute_reply.started": "2022-02-26T19:57:58.246654Z",
          "shell.execute_reply": "2022-02-26T19:57:58.253135Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(chromaClassical, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Chromagram of a Classical type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(chromaBlues, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Chromagram of an Blues type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
      ],
      "metadata": {
        "id": "SaGkC5eN8GlB",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:58.255100Z",
          "iopub.execute_input": "2022-02-26T19:57:58.255375Z",
          "iopub.status.idle": "2022-02-26T19:57:58.800038Z",
          "shell.execute_reply.started": "2022-02-26T19:57:58.255342Z",
          "shell.execute_reply": "2022-02-26T19:57:58.799360Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(chromaClassicalBeat, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Chromagram of a Classical type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(chromaBluesBeat, x_axis='time', y_axis='linear', ax=ax)\n",
        "ax.set(title='Chromagram of an Blues type')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
      ],
      "metadata": {
        "id": "8EaXiO_M8GlC",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:58.801405Z",
          "iopub.execute_input": "2022-02-26T19:57:58.802159Z",
          "iopub.status.idle": "2022-02-26T19:57:59.274821Z",
          "shell.execute_reply.started": "2022-02-26T19:57:58.802117Z",
          "shell.execute_reply": "2022-02-26T19:57:59.274116Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 4"
      ],
      "metadata": {
        "id": "VoEmYX_G8GlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "\n",
        "# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well\n",
        "CLASS_MAPPING = {\n",
        "    \"Rock\": \"Rock\",\n",
        "    \"Psych-Rock\": \"Rock\",\n",
        "    \"Indie-Rock\": None,\n",
        "    \"Post-Rock\": \"Rock\",\n",
        "    \"Psych-Folk\": \"Folk\",\n",
        "    \"Folk\": \"Folk\",\n",
        "    \"Metal\": \"Metal\",\n",
        "    \"Punk\": \"Metal\",\n",
        "    \"Post-Punk\": None,\n",
        "    \"Trip-Hop\": \"Trip-Hop\",\n",
        "    \"Pop\": \"Pop\",\n",
        "    \"Electronic\": \"Electronic\",\n",
        "    \"Hip-Hop\": \"Hip-Hop\",\n",
        "    \"Classical\": \"Classical\",\n",
        "    \"Blues\": \"Blues\",\n",
        "    \"Chiptune\": \"Electronic\",\n",
        "    \"Jazz\": \"Jazz\",\n",
        "    \"Soundtrack\": None,\n",
        "    \"International\": None,\n",
        "    \"Old-Time\": None,\n",
        "}\n",
        "\n",
        "\n",
        "def torch_train_val_split(\n",
        "    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420\n",
        "):\n",
        "    # Creating data indices for training and validation splits:\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    val_split = int(np.floor(val_size * dataset_size))\n",
        "    if shuffle:\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices = indices[val_split:]\n",
        "    val_indices = indices[:val_split]\n",
        "\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n",
        "    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "def read_spectrogram(spectrogram_file, chroma=False, mel = False):\n",
        "    # with open(spectrogram_file, \"r\") as f:\n",
        "    if chroma == False and mel == False:\n",
        "        spectrograms = np.load(spectrogram_file)\n",
        "    elif mel == True:\n",
        "        spectrograms = np.load(spectrogram_file)[:128]\n",
        "    else:\n",
        "        spectrograms = np.load(spectrogram_file)[128:]\n",
        "    # spectrograms contains a fused mel spectrogram and chromagram\n",
        "    # Decompose as follows\n",
        "    return spectrograms.T\n",
        "\n",
        "\n",
        "class LabelTransformer(LabelEncoder):\n",
        "    def inverse(self, y):\n",
        "        try:\n",
        "            return super(LabelTransformer, self).inverse_transform(y)\n",
        "        except:\n",
        "            return super(LabelTransformer, self).inverse_transform([y])\n",
        "\n",
        "    def transform(self, y):\n",
        "        try:\n",
        "            return super(LabelTransformer, self).transform(y)\n",
        "        except:\n",
        "            return super(LabelTransformer, self).transform([y])\n",
        "\n",
        "\n",
        "class PaddingTransform(object):\n",
        "    def __init__(self, max_length, padding_value=0):\n",
        "        self.max_length = max_length\n",
        "        self.padding_value = padding_value\n",
        "\n",
        "    def __call__(self, s):\n",
        "        if len(s) == self.max_length:\n",
        "            return s\n",
        "\n",
        "        if len(s) > self.max_length:\n",
        "            return s[: self.max_length]\n",
        "\n",
        "        if len(s) < self.max_length:\n",
        "            s1 = copy.deepcopy(s)\n",
        "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
        "            s1 = np.vstack((s1, pad))\n",
        "            return s1\n",
        "\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, path, class_mapping=None, train=True, max_length=-1, regression=None, chroma = False, mel = False\n",
        "    ):\n",
        "        t = \"train\" if train else \"test\"\n",
        "        p = os.path.join(path, t)\n",
        "        self.regression = regression\n",
        "\n",
        "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
        "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
        "        self.feats = [read_spectrogram(os.path.join(p, f), chroma, mel) for f in self.files]\n",
        "        self.feat_dim = self.feats[0].shape[1]\n",
        "        self.lengths = [len(i) for i in self.feats]\n",
        "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
        "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
        "        self.label_transformer = LabelTransformer()\n",
        "        if isinstance(labels, (list, tuple)):\n",
        "            if not regression:\n",
        "                self.labels = np.array(\n",
        "                    self.label_transformer.fit_transform(labels)\n",
        "                ).astype(\"int64\")\n",
        "            else:\n",
        "                self.labels = np.array(labels).astype(\"float64\")\n",
        "\n",
        "    def get_files_labels(self, txt, class_mapping):\n",
        "        # Returns a list of file names and a list of their labels\n",
        "        with open(txt, 'r') as fd:\n",
        "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
        "        files, labels = [], []\n",
        "        for l in lines:\n",
        "            label = l[1]\n",
        "            if class_mapping:\n",
        "                label = class_mapping[l[1]]\n",
        "            if not label:\n",
        "                continue\n",
        "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
        "            _id = l[0].split('.')[0]\n",
        "            npy_file = '{}.fused.full.npy'.format(_id)\n",
        "            files.append(npy_file)\n",
        "            labels.append(label)\n",
        "            \n",
        "        return files, labels\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        length = min(self.lengths[item], self.max_length)\n",
        "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ##################################################################################\n",
        "    # load fused speectrogram + chromagram for the full (non-beat-synced) data\n",
        "    ##################################################################################\n",
        "    specs_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,\n",
        "                                     class_mapping=CLASS_MAPPING, max_length=-1)\n",
        "    train_loader, val_loader = torch_train_val_split(specs_fused, 32, 32, val_size=.33)\n",
        "    test_dataset = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,\n",
        "                                     class_mapping=CLASS_MAPPING, max_length=-1)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "    \n",
        "    ##################################################################################\n",
        "    # load single synced mel spectrograms\n",
        "    ##################################################################################\n",
        "    # Dataset\n",
        "    mel_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,\n",
        "                                        class_mapping=CLASS_MAPPING, max_length=-1,mel = True)\n",
        "    # Train and Test loaders\n",
        "    train_loader_mel, val_loader_mel = torch_train_val_split(mel_specs, 32, 32, val_size=.33)\n",
        "    test_dataset_mel = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,\n",
        "                                            class_mapping=CLASS_MAPPING, max_length=-1,mel = True)\n",
        "    \n",
        "    test_loader_mel = DataLoader(test_dataset_mel, batch_size=1)\n",
        "    \n",
        "    ##################################################################################\n",
        "    # load beat synced mel spectrograms\n",
        "    ##################################################################################\n",
        "    # Dataset\n",
        "    beat_mel_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,\n",
        "                                         class_mapping=CLASS_MAPPING, max_length=-1,mel = True)\n",
        "    # Train and Test loaders\n",
        "    train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_specs, 32, 32, val_size=.33)\n",
        "    test_dataset_beat_mel = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,\n",
        "                                                 class_mapping=CLASS_MAPPING, max_length=-1,mel = True)\n",
        "    test_loader_beat_mel = DataLoader(test_dataset_beat_mel, batch_size=1)\n",
        "    \n",
        "    ##################################################################################\n",
        "    # load beat synced chroma chromagrams\n",
        "    ##################################################################################\n",
        "    beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,\n",
        "                                     class_mapping=CLASS_MAPPING, max_length=-1,chroma = True)\n",
        "    train_loader_beat_chroma, val_loader_beat_chroma = torch_train_val_split(beat_chroma, 32, 32, val_size=.33)\n",
        "    test_dataset_beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,\n",
        "                                                 class_mapping=CLASS_MAPPING, max_length=-1,chroma = True)\n",
        "    test_loader_beat_chroma = DataLoader(test_dataset_beat_chroma, batch_size=1)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "RXPlu9Co8GlD",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:57:59.276297Z",
          "iopub.execute_input": "2022-02-26T19:57:59.276735Z",
          "iopub.status.idle": "2022-02-26T19:59:04.909233Z",
          "shell.execute_reply.started": "2022-02-26T19:57:59.276696Z",
          "shell.execute_reply": "2022-02-26T19:59:04.908432Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Πριν την ομαδοποίηση των κλάσεων**"
      ],
      "metadata": {
        "id": "iBUcRxuI8GlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "# Train labels\n",
        "file = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train_labels.txt', 'r') \n",
        "for line in file.readlines()[1:]: \n",
        "    label = line.split()[1]\n",
        "    y_train.append(label)\n",
        "    \n",
        "# Test labels\n",
        "file = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/test_labels.txt', 'r') \n",
        "for line in file.readlines()[1:]: \n",
        "    label = line.split()[1]\n",
        "    y_test.append(label)\n",
        "unique_train = np.unique(np.array(y_train))\n",
        "unique_test = np.unique(np.array(y_test))\n",
        "print(unique_train)\n",
        "print(unique_test)"
      ],
      "metadata": {
        "id": "1xYiVA0B8GlK",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:04.911373Z",
          "iopub.execute_input": "2022-02-26T19:59:04.911747Z",
          "iopub.status.idle": "2022-02-26T19:59:04.926573Z",
          "shell.execute_reply.started": "2022-02-26T19:59:04.911710Z",
          "shell.execute_reply": "2022-02-26T19:59:04.925850Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(24,8))\n",
        "plt.title('Histogram of unprocessed classes for the training set')\n",
        "plt.hist(y_train, bins=len(unique_train), rwidth=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q3zhpZgz8GlL",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:04.927760Z",
          "iopub.execute_input": "2022-02-26T19:59:04.928021Z",
          "iopub.status.idle": "2022-02-26T19:59:05.227658Z",
          "shell.execute_reply.started": "2022-02-26T19:59:04.927985Z",
          "shell.execute_reply": "2022-02-26T19:59:05.226989Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(24,8))\n",
        "plt.title('Histogram of unprocessed classes for the testing set')\n",
        "plt.hist(y_test, bins=len(unique_test), rwidth=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DcBmLqfZ8GlR",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.229017Z",
          "iopub.execute_input": "2022-02-26T19:59:05.229808Z",
          "iopub.status.idle": "2022-02-26T19:59:05.513921Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.229759Z",
          "shell.execute_reply": "2022-02-26T19:59:05.513244Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Μετά την ομαδοποίηση των κλάσεων**"
      ],
      "metadata": {
        "id": "Yd6UvTzI8GlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "file = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train_labels.txt', 'r') \n",
        "for line in file.readlines()[1:]: \n",
        "    label = line.split()[1]\n",
        "    if CLASS_MAPPING[label] is not None:\n",
        "        y_train.append(CLASS_MAPPING[label])\n",
        "    \n",
        "file = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/test_labels.txt', 'r') \n",
        "for line in file.readlines()[1:]: \n",
        "    label = line.split()[1]\n",
        "    if CLASS_MAPPING[label] is not None:\n",
        "        y_test.append(CLASS_MAPPING[label])\n",
        "unique_train = np.unique(np.array(y_train))\n",
        "unique_test = np.unique(np.array(y_test))\n",
        "print(unique_train)\n",
        "print(unique_test)"
      ],
      "metadata": {
        "id": "xgANvDKP8GlV",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.515042Z",
          "iopub.execute_input": "2022-02-26T19:59:05.515299Z",
          "iopub.status.idle": "2022-02-26T19:59:05.531415Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.515255Z",
          "shell.execute_reply": "2022-02-26T19:59:05.530332Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Histogram of processed classes for the training set')\n",
        "plt.hist(y_train, bins=len(unique_train), rwidth=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "or8pVCYi8GlY",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.532566Z",
          "iopub.execute_input": "2022-02-26T19:59:05.532883Z",
          "iopub.status.idle": "2022-02-26T19:59:05.758426Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.532845Z",
          "shell.execute_reply": "2022-02-26T19:59:05.757748Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "plt.title('Histogram of processed classes for the testing set')\n",
        "plt.hist(y_train, bins=len(unique_test), rwidth=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ncj6vKDv8Glb",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.759483Z",
          "iopub.execute_input": "2022-02-26T19:59:05.759717Z",
          "iopub.status.idle": "2022-02-26T19:59:05.981977Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.759685Z",
          "shell.execute_reply": "2022-02-26T19:59:05.981262Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 5"
      ],
      "metadata": {
        "id": "ITN7NfPW8Glb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class PadPackedSequence(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Wrap sequence padding in nn.Module\n",
        "        Args:\n",
        "            batch_first (bool, optional): Use batch first representation. Defaults to True.\n",
        "        \"\"\"\n",
        "        super(PadPackedSequence, self).__init__()\n",
        "        self.batch_first = True\n",
        "        self.max_length = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Convert packed sequence to padded sequence\n",
        "        Args:\n",
        "            x (torch.nn.utils.rnn.PackedSequence): Packed sequence\n",
        "        Returns:\n",
        "            torch.Tensor: Padded sequence\n",
        "        \"\"\"\n",
        "        out, lengths = pad_packed_sequence(\n",
        "            x, batch_first=self.batch_first, total_length=self.max_length  # type: ignore\n",
        "        )\n",
        "        lengths = lengths.to(out.device)\n",
        "        return out, lengths  # type: ignore\n",
        "\n",
        "\n",
        "class PackSequence(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Wrap sequence packing in nn.Module\n",
        "        Args:\n",
        "            batch_first (bool, optional): Use batch first representation. Defaults to True.\n",
        "        \"\"\"\n",
        "        super(PackSequence, self).__init__()\n",
        "        self.batch_first = True\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        \"\"\"Pack a padded sequence and sort lengths\n",
        "        Args:\n",
        "            x (torch.Tensor): Padded tensor\n",
        "            lengths (torch.Tensor): Original lengths befor padding\n",
        "        Returns:\n",
        "            Tuple[torch.nn.utils.rnn.PackedSequence, torch.Tensor]: (packed sequence, sorted lengths)\n",
        "        \"\"\"\n",
        "        lengths = lengths.to(\"cpu\")\n",
        "        out = pack_padded_sequence(\n",
        "            x, lengths, batch_first=self.batch_first, enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "fv2dttts8Glc",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.983143Z",
          "iopub.execute_input": "2022-02-26T19:59:05.984029Z",
          "iopub.status.idle": "2022-02-26T19:59:05.994394Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.983984Z",
          "shell.execute_reply": "2022-02-26T19:59:05.993536Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMBackbone(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        rnn_size=128,\n",
        "        num_layers=1,\n",
        "        bidirectional=False,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(LSTMBackbone, self).__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.rnn_size = rnn_size\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = rnn_size\n",
        "        self.pack = PackSequence()\n",
        "        self.unpack = PadPackedSequence()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=rnn_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=self.bidirectional,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x, lengths):\n",
        "        \"\"\"LSTM forward\n",
        "        Args:\n",
        "            x (torch.Tensor):\n",
        "                [B, S, F] Batch size x sequence length x feature size\n",
        "                padded inputs\n",
        "            lengths (torch.tensor):\n",
        "                [B] Original lengths of each padded sequence in the batch\n",
        "        Returns:\n",
        "            torch.Tensor:\n",
        "                [B, H] Batch size x hidden size lstm last timestep outputs\n",
        "                2 x hidden_size if bidirectional\n",
        "        \"\"\"\n",
        "        packed = self.pack(x, lengths)\n",
        "        output, _ = self.lstm(packed)\n",
        "        output, lengths = self.unpack(output)\n",
        "        output = self.drop(output)\n",
        "\n",
        "        rnn_all_outputs, last_timestep = self._final_output(output, lengths)\n",
        "        # Use the last_timestep for classification / regression\n",
        "        # Alternatively rnn_all_outputs can be used with an attention mechanism\n",
        "        return last_timestep\n",
        "    def _merge_bi(self, forward, backward):\n",
        "        \"\"\"Merge forward and backward states\n",
        "        Args:\n",
        "            forward (torch.Tensor): [B, L, H] Forward states\n",
        "            backward (torch.Tensor): [B, L, H] Backward states\n",
        "        Returns:\n",
        "            torch.Tensor: [B, L, 2*H] Merged forward and backward states\n",
        "        \"\"\"\n",
        "        return torch.cat((forward, backward), dim=-1)\n",
        "\n",
        "    def _final_output(self, out, lengths):\n",
        "        \"\"\"Create RNN ouputs\n",
        "        Collect last hidden state for forward and backward states\n",
        "        Code adapted from https://stackoverflow.com/a/50950188\n",
        "        Args:\n",
        "            out (torch.Tensor): [B, L, num_directions * H] RNN outputs\n",
        "            lengths (torch.Tensor): [B] Original sequence lengths\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: (\n",
        "                merged forward and backward states [B, L, H] or [B, L, 2*H],\n",
        "                merged last forward and backward state [B, H] or [B, 2*H]\n",
        "            )\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.bidirectional:\n",
        "            return out, self._select_last_unpadded(out, lengths)\n",
        "\n",
        "        forward, backward = (out[..., : self.hidden_size], out[..., self.hidden_size :])\n",
        "        # Last backward corresponds to first token\n",
        "        last_backward_out = backward[:, 0, :]\n",
        "        # Last forward for real length or seq (unpadded tokens)\n",
        "        last_forward_out = self._select_last_unpadded(forward, lengths)\n",
        "        out = self._merge_bi(forward, backward)\n",
        "\n",
        "        return out, self._merge_bi(last_forward_out, last_backward_out)\n",
        "\n",
        "    def _select_last_unpadded(self, out, lengths):\n",
        "        \"\"\"Get the last timestep before padding starts\n",
        "        Args:\n",
        "            out (torch.Tensor): [B, L, H] Fprward states\n",
        "            lengths (torch.Tensor): [B] Original sequence lengths\n",
        "        Returns:\n",
        "            torch.Tensor: [B, H] Features for last sequence timestep\n",
        "        \"\"\"\n",
        "        gather_dim = 1  # Batch first\n",
        "        gather_idx = (\n",
        "            (lengths - 1)  # -1 to convert to indices\n",
        "            .unsqueeze(1)  # (B) -> (B, 1)\n",
        "            .expand((-1, self.hidden_size))  # (B, 1) -> (B, H)\n",
        "            # (B, 1, H) if batch_first else (1, B, H)\n",
        "            .unsqueeze(gather_dim)\n",
        "        )\n",
        "        # Last forward for real length or seq (unpadded tokens)\n",
        "        last_out = out.gather(gather_dim, gather_idx).squeeze(gather_dim)\n",
        "\n",
        "        return last_out"
      ],
      "metadata": {
        "id": "58swalb48Gld",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:05.996904Z",
          "iopub.execute_input": "2022-02-26T19:59:05.997484Z",
          "iopub.status.idle": "2022-02-26T19:59:06.014319Z",
          "shell.execute_reply.started": "2022-02-26T19:59:05.997442Z",
          "shell.execute_reply": "2022-02-26T19:59:06.013562Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_LSTM(train_set, val_set, input_size):\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Hyper-parameters\n",
        "    input_size = input_size\n",
        "    rnn_size = 100\n",
        "    num_layers = 2\n",
        "    num_epochs = 100\n",
        "    bidirectional = True\n",
        "    \n",
        "    min_val_loss = np.Inf\n",
        "    earlystop = 10\n",
        "    no_improve_in_val = 0\n",
        "\n",
        "    model = LSTMBackbone(input_size, rnn_size, num_layers, bidirectional=bidirectional)\n",
        "    model.to(device)\n",
        "    model = model.double()\n",
        "    best_model = model\n",
        "    # Loss and optimizer\n",
        "    loss_function  = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        # Οbtain the model's device ID\n",
        "        device = next(model.parameters()).device\n",
        "        for index, batch in enumerate(train_set):\n",
        "            features, labels, lengths = batch\n",
        "\n",
        "            # Move the batch tensors to the right device\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Step 1 - zero the gradients\n",
        "            # Remember that PyTorch accumulates gradients.\n",
        "            # We need to clear them out before each batch!\n",
        "            optimizer.zero_grad()\n",
        "            # Step 2 - forward pass: y' = model(x)\n",
        "            y_preds = model(features, lengths)\n",
        "            # Step 3 - compute loss: L = loss_function(y, y')\n",
        "            loss = loss_function(y_preds, labels)\n",
        "            # Step 4 - backward pass: compute gradient wrt model parameters\n",
        "            loss.backward()\n",
        "            # Step 5 - update weights\n",
        "            optimizer.step()\n",
        "            # Accumulate loss in a variable.\n",
        "            train_loss += loss.data.item()\n",
        "        train_loss = train_loss / index\n",
        "        model.eval()\n",
        "        validation_loss = 0.0\n",
        "        y_pred = []  # the predicted labels\n",
        "        y = []  # the gold labels\n",
        "        # Obtain the model's device ID\n",
        "        device = next(model.parameters()).device\n",
        "        # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n",
        "        # so we do everything under torch.no_grad()\n",
        "        with torch.no_grad():\n",
        "            for index, batch in enumerate(val_set):\n",
        "                # Get the inputs (batch)\n",
        "                features, labels, lengths = batch\n",
        "                # Step 1 - move the batch tensors to the right device\n",
        "                features = features.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # Step 2 - forward pass: y' = model(x)\n",
        "                y_preds = model(features, lengths)  # EX9\n",
        "                # Step 3 - compute loss: L = loss_function(y, y')\n",
        "                # We compute the loss only for inspection (compare train/test loss)\n",
        "                # because we do not actually backpropagate in test time\n",
        "                loss = loss_function(y_preds, labels)\n",
        "                # Step 4 - make predictions (class = argmax of posteriors)\n",
        "                y_preds_arg = torch.argmax(y_preds, dim=1)\n",
        "                # Step 5 - collect the predictions, gold labels and batch loss\n",
        "                y_pred.append(y_preds_arg.cpu().numpy())\n",
        "                y.append(labels.cpu().numpy())\n",
        "                # Accumulate loss in a variable\n",
        "                validation_loss += loss.data.item()\n",
        "        validation_loss = validation_loss/index\n",
        "        if validation_loss <= min_val_loss:\n",
        "            no_improve_in_val = 0\n",
        "            best_model = model\n",
        "        else:\n",
        "            no_improve_in_val += 1\n",
        "        if no_improve_in_val == earlystop:\n",
        "            break\n",
        "        if epoch%5 == 0 or epoch == 49: \n",
        "            print(\"For Epoch\",epoch, ':', 'Train loss =', train_loss, 'and Validation loss =', validation_loss)\n",
        "            print()\n",
        "    return best_model\n",
        "   "
      ],
      "metadata": {
        "id": "fDZfq4Qs8Glf",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:06.017353Z",
          "iopub.execute_input": "2022-02-26T19:59:06.017560Z",
          "iopub.status.idle": "2022-02-26T19:59:06.035927Z",
          "shell.execute_reply.started": "2022-02-26T19:59:06.017527Z",
          "shell.execute_reply": "2022-02-26T19:59:06.035240Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate(test_loader, model):\n",
        "    model.eval()\n",
        "\n",
        "    y_pred = []  # the predicted labels\n",
        "    y = []  # the gold labels\n",
        "    # Obtain the model's device ID\n",
        "    device = next(model.parameters()).device\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(test_loader):\n",
        "            # Get the inputs (batch)\n",
        "            inputs, labels, lengths = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            y_preds = model(inputs, lengths) \n",
        "            y_preds_arg = torch.argmax(y_preds, dim=1)\n",
        "            y_pred.append(y_preds_arg.cpu().numpy())\n",
        "            y.append(labels.cpu().numpy())\n",
        "    print(classification_report(y, y_pred))"
      ],
      "metadata": {
        "id": "sY2HD-BD8Glh",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:06.038652Z",
          "iopub.execute_input": "2022-02-26T19:59:06.038935Z",
          "iopub.status.idle": "2022-02-26T19:59:06.048795Z",
          "shell.execute_reply.started": "2022-02-26T19:59:06.038898Z",
          "shell.execute_reply": "2022-02-26T19:59:06.047967Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 6"
      ],
      "metadata": {
        "id": "tpr0O5tUzspM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Εκπαίδευση με τα Spectrograms**"
      ],
      "metadata": {
        "id": "OIlizQVu8Gli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_LSTM(train_loader_mel, val_loader_mel, 128)"
      ],
      "metadata": {
        "id": "4Wyt2Otu8Gli",
        "execution": {
          "iopub.status.busy": "2022-02-26T19:59:06.050075Z",
          "iopub.execute_input": "2022-02-26T19:59:06.051040Z",
          "iopub.status.idle": "2022-02-26T20:44:49.337415Z",
          "shell.execute_reply.started": "2022-02-26T19:59:06.050997Z",
          "shell.execute_reply": "2022-02-26T20:44:49.336302Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader_mel, model)"
      ],
      "metadata": {
        "id": "ZKElQJGH8Glj",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:44:49.338956Z",
          "iopub.execute_input": "2022-02-26T20:44:49.339281Z",
          "iopub.status.idle": "2022-02-26T20:45:25.138506Z",
          "shell.execute_reply.started": "2022-02-26T20:44:49.339230Z",
          "shell.execute_reply": "2022-02-26T20:45:25.137714Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Εκπαίδευση με Beat-Synced Spectograms**"
      ],
      "metadata": {
        "id": "RAYbmRVR8Glj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_LSTM(train_loader_beat_mel, val_loader_beat_mel, 128)"
      ],
      "metadata": {
        "id": "OY5nI9CN8Glk",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:45:25.142934Z",
          "iopub.execute_input": "2022-02-26T20:45:25.143571Z",
          "iopub.status.idle": "2022-02-26T20:48:51.477886Z",
          "shell.execute_reply.started": "2022-02-26T20:45:25.143531Z",
          "shell.execute_reply": "2022-02-26T20:48:51.477200Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader_beat_mel, model)"
      ],
      "metadata": {
        "id": "1BnSW7cV8Glk",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:48:51.479345Z",
          "iopub.execute_input": "2022-02-26T20:48:51.479594Z",
          "iopub.status.idle": "2022-02-26T20:48:53.621672Z",
          "shell.execute_reply.started": "2022-02-26T20:48:51.479560Z",
          "shell.execute_reply": "2022-02-26T20:48:53.620880Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Εκπαίδευση με Beat-Synced Χρωμογραφήματα**"
      ],
      "metadata": {
        "id": "jhWPHpEl8Gll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_LSTM(train_loader_beat_chroma, val_loader_beat_chroma, 12)"
      ],
      "metadata": {
        "id": "LfLOztsP8Gll",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:48:53.623107Z",
          "iopub.execute_input": "2022-02-26T20:48:53.623520Z",
          "iopub.status.idle": "2022-02-26T20:51:59.173262Z",
          "shell.execute_reply.started": "2022-02-26T20:48:53.623483Z",
          "shell.execute_reply": "2022-02-26T20:51:59.172517Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader_beat_chroma, model)"
      ],
      "metadata": {
        "id": "K7bsIg538Glm",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:51:59.174450Z",
          "iopub.execute_input": "2022-02-26T20:51:59.176314Z",
          "iopub.status.idle": "2022-02-26T20:52:01.319933Z",
          "shell.execute_reply.started": "2022-02-26T20:51:59.176284Z",
          "shell.execute_reply": "2022-02-26T20:52:01.319214Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Εκπαίδευση με Χρωμογραφήματα και Φασματογραφήματα**"
      ],
      "metadata": {
        "id": "iMtHiU4m8Gln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_LSTM(train_loader, val_loader, 140)"
      ],
      "metadata": {
        "id": "UV0qE7-z8Gln",
        "execution": {
          "iopub.status.busy": "2022-02-26T20:52:01.321467Z",
          "iopub.execute_input": "2022-02-26T20:52:01.322142Z",
          "iopub.status.idle": "2022-02-26T21:38:44.374212Z",
          "shell.execute_reply.started": "2022-02-26T20:52:01.322104Z",
          "shell.execute_reply": "2022-02-26T21:38:44.373464Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "id": "DTjq4xtA8Glo",
        "execution": {
          "iopub.status.busy": "2022-02-26T21:38:44.375808Z",
          "iopub.execute_input": "2022-02-26T21:38:44.376032Z",
          "iopub.status.idle": "2022-02-26T21:39:19.891142Z",
          "shell.execute_reply.started": "2022-02-26T21:38:44.376000Z",
          "shell.execute_reply": "2022-02-26T21:39:19.889876Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Βήμα 7"
      ],
      "metadata": {
        "id": "xEYU6eETxFPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some useful functions for loading spectrograms and chromagrams\n",
        "\n",
        "def read_fused_spectrogram(spectrogram_file):\n",
        "    spectrogram = np.load(spectrogram_file)\n",
        "    return spectrogram.T\n",
        "\n",
        "\n",
        "def read_mel_spectrogram(spectrogram_file):\n",
        "    spectrogram = np.load(spectrogram_file)[:128]\n",
        "    return spectrogram.T\n",
        "\n",
        "    \n",
        "def read_chromagram(spectrogram_file):\n",
        "    spectrogram = np.load(spectrogram_file)[128:]\n",
        "    return spectrogram.T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:26:38.849241Z",
          "iopub.execute_input": "2022-02-27T14:26:38.849491Z",
          "iopub.status.idle": "2022-02-27T14:26:38.858732Z",
          "shell.execute_reply.started": "2022-02-27T14:26:38.849454Z",
          "shell.execute_reply": "2022-02-27T14:26:38.858091Z"
        },
        "trusted": true,
        "id": "41WbT8Bpqn6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an encoder for the labels\n",
        "\n",
        "class LabelTransformer(LabelEncoder):\n",
        "    def inverse(self, y):\n",
        "        try:\n",
        "            return super(LabelTransformer, self).inverse_transform(y)\n",
        "        except:\n",
        "            return super(LabelTransformer, self).inverse_transform([y])\n",
        "\n",
        "    def transform(self, y):\n",
        "        try:\n",
        "            return super(LabelTransformer, self).transform(y)\n",
        "        except:\n",
        "            return super(LabelTransformer, self).transform([y])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:26:38.860266Z",
          "iopub.execute_input": "2022-02-27T14:26:38.860899Z",
          "iopub.status.idle": "2022-02-27T14:26:38.868604Z",
          "shell.execute_reply.started": "2022-02-27T14:26:38.860856Z",
          "shell.execute_reply": "2022-02-27T14:26:38.867872Z"
        },
        "trusted": true,
        "id": "BVoNKbftqn6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PaddingTransformer in order to convert all input sequences to the same length\n",
        "\n",
        "class PaddingTransform(object):\n",
        "    def __init__(self, max_length, padding_value=0):\n",
        "        self.max_length = max_length\n",
        "        self.padding_value = padding_value\n",
        "\n",
        "    def __call__(self, s):\n",
        "        if len(s) == self.max_length:\n",
        "            return s\n",
        "\n",
        "        if len(s) > self.max_length:\n",
        "            return s[:self.max_length]\n",
        "\n",
        "        if len(s) < self.max_length:\n",
        "            s1 = copy.deepcopy(s)\n",
        "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
        "            s1 = np.vstack((s1, pad))\n",
        "            return s1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:26:38.869749Z",
          "iopub.execute_input": "2022-02-27T14:26:38.870090Z",
          "iopub.status.idle": "2022-02-27T14:26:38.879717Z",
          "shell.execute_reply.started": "2022-02-27T14:26:38.870053Z",
          "shell.execute_reply": "2022-02-27T14:26:38.879053Z"
        },
        "trusted": true,
        "id": "rpbko62nqn6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define useful parameters that are the same for all the models.\n",
        "\n",
        "num_mel = 128\n",
        "num_chroma = 12\n",
        "n_classes = 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:26:38.880940Z",
          "iopub.execute_input": "2022-02-27T14:26:38.881143Z",
          "iopub.status.idle": "2022-02-27T14:26:38.889330Z",
          "shell.execute_reply.started": "2022-02-27T14:26:38.881118Z",
          "shell.execute_reply": "2022-02-27T14:26:38.888723Z"
        },
        "trusted": true,
        "id": "znCrArMSqn6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
        "        t = 'train' if train else 'test'\n",
        "        p = os.path.join(path, t)\n",
        "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
        "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
        "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
        "        self.feat_dim = self.feats[0].shape[1]\n",
        "        self.lengths = [len(i) for i in self.feats]\n",
        "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
        "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
        "        self.label_transformer = LabelTransformer()\n",
        "        if isinstance(labels, (list, tuple)):\n",
        "            self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')\n",
        "\n",
        "    def get_files_labels(self, txt, class_mapping):\n",
        "        with open(txt, 'r') as fd:\n",
        "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
        "        files, labels = [], []\n",
        "        for l in lines:\n",
        "            label = l[1]\n",
        "            if class_mapping:\n",
        "                label = class_mapping[l[1]]\n",
        "            if not label:\n",
        "                continue\n",
        "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
        "            _id = l[0].split('.')[0]\n",
        "            npy_file = '{}.fused.full.npy'.format(_id)\n",
        "            files.append(npy_file)\n",
        "            labels.append(label)\n",
        "        return files, labels\n",
        "    \n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # Return a tuple in the form (padded_feats, label, length)\n",
        "        l = min(self.lengths[item], self.max_length)\n",
        "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:14.725908Z",
          "iopub.execute_input": "2022-02-27T13:12:14.726291Z",
          "iopub.status.idle": "2022-02-27T13:12:14.742294Z",
          "shell.execute_reply.started": "2022-02-27T13:12:14.726253Z",
          "shell.execute_reply": "2022-02-27T13:12:14.741328Z"
        },
        "trusted": true,
        "id": "kfQMJ7LCqn6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mel Spectograms**"
      ],
      "metadata": {
        "id": "1wfeZalMqn6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel_specs = SpectrogramDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',\n",
        "         train=True,\n",
        "         class_mapping=CLASS_MAPPING,\n",
        "         max_length=-1,\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "train_loader_mel, val_loader_mel = torch_train_val_split(mel_specs, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:14.744066Z",
          "iopub.execute_input": "2022-02-27T13:12:14.745180Z",
          "iopub.status.idle": "2022-02-27T13:12:50.461759Z",
          "shell.execute_reply.started": "2022-02-27T13:12:14.745141Z",
          "shell.execute_reply": "2022-02-27T13:12:50.461018Z"
        },
        "trusted": true,
        "id": "leXCS_5vqn6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mel = SpectrogramDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',\n",
        "         train=False,\n",
        "         class_mapping=CLASS_MAPPING,\n",
        "         max_length=1293,\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "test_loader_mel = DataLoader(test_mel, batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:50.473561Z",
          "iopub.execute_input": "2022-02-27T13:12:50.473829Z",
          "iopub.status.idle": "2022-02-27T13:12:58.832143Z",
          "shell.execute_reply.started": "2022-02-27T13:12:50.473786Z",
          "shell.execute_reply": "2022-02-27T13:12:58.831323Z"
        },
        "trusted": true,
        "id": "iHtA3mC8qn6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Per Epoch.\n",
        "\n",
        "def train_dataset(_epoch, dataloader, model, loss_function, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    for index, batch in enumerate(dataloader, 1):\n",
        "        # Get the inputs (batch)\n",
        "        inputs, labels, lengths = batch\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_preds = model(inputs, lengths)\n",
        "        \n",
        "        loss = loss_function(y_preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.data.item()\n",
        "\n",
        "    return running_loss / index"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:58.930040Z",
          "iopub.execute_input": "2022-02-27T13:12:58.930227Z",
          "iopub.status.idle": "2022-02-27T13:12:58.939008Z",
          "shell.execute_reply.started": "2022-02-27T13:12:58.930205Z",
          "shell.execute_reply": "2022-02-27T13:12:58.938350Z"
        },
        "trusted": true,
        "id": "w0mmHJCiqn6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Per Epoch\n",
        "def eval_dataset(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    y_pred = []  \n",
        "    y = []\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(dataloader, 1):\n",
        "            inputs, labels, lengths = batch\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            y_preds = model(inputs, lengths)\n",
        "\n",
        "            loss = loss_function(y_preds, labels)\n",
        "            y_preds_arg = torch.argmax(y_preds, dim=1)\n",
        "\n",
        "            y_pred.append(y_preds_arg.cpu().numpy())\n",
        "            y.append(labels.cpu().numpy())\n",
        "\n",
        "            # Accumulate loss in a variable\n",
        "            running_loss += loss.data.item()\n",
        "\n",
        "    return running_loss / index, (y, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:58.941975Z",
          "iopub.execute_input": "2022-02-27T13:12:58.942172Z",
          "iopub.status.idle": "2022-02-27T13:12:58.952995Z",
          "shell.execute_reply.started": "2022-02-27T13:12:58.942143Z",
          "shell.execute_reply": "2022-02-27T13:12:58.952153Z"
        },
        "trusted": true,
        "id": "guCZLTl0qn6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
        "        self.conv1_bn = nn.BatchNorm2d(3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2_bn = nn.BatchNorm2d(6)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(6, 8, 3)\n",
        "        self.conv3_bn = nn.BatchNorm2d(8)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(8, 12, 3)\n",
        "        self.conv4_bn = nn.BatchNorm2d(12)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "                \n",
        "        self.fc1 = nn.Linear(4680, 128)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x.view(x.size(0), 1, x.size(1), x.size(2))\n",
        "        \n",
        "        x = self.pool1(F.relu( self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool2(F.relu( self.conv2_bn(self.conv2(x))))\n",
        "        x = self.pool3(F.relu( self.conv3_bn(self.conv3(x))))\n",
        "        x = self.pool4(F.relu( self.conv4_bn(self.conv4(x))))\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:58.956118Z",
          "iopub.execute_input": "2022-02-27T13:12:58.956857Z",
          "iopub.status.idle": "2022-02-27T13:12:58.970116Z",
          "shell.execute_reply.started": "2022-02-27T13:12:58.956825Z",
          "shell.execute_reply": "2022-02-27T13:12:58.969330Z"
        },
        "trusted": true,
        "id": "_Og6c56wqn6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "model = ConvNet()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "n_epochs_stop = 10\n",
        "min_val_loss = 1000\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train the model for one epoch\n",
        "    train_dataset(epoch, train_loader_mel, model, loss_function, optimizer)\n",
        "    \n",
        "    # Evaluate the performance of the model, on both data sets\n",
        "    train_loss, (y_train_gold, y_train_pred) = eval_dataset(train_loader_mel, model, loss_function)\n",
        "\n",
        "    val_loss, (y_val_gold, y_val_pred) = eval_dataset(val_loader_mel, model, loss_function)\n",
        "    \n",
        "    if val_loss < min_val_loss:\n",
        "        # Save the model\n",
        "        torch.save(model, \"./mel_cnn\")\n",
        "        epochs_no_improve = 0\n",
        "        min_val_loss = val_loss\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "            \n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "        print('Early stopping!')\n",
        "        break\n",
        "        \n",
        "    y_train_true = np.concatenate( y_train_gold, axis=0 )\n",
        "    y_val_true = np.concatenate( y_val_gold, axis=0 )\n",
        "    y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "    y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "    print(\"Epoch \", epoch)\n",
        "    print(\"Train loss: \", train_loss)\n",
        "    print(\"Validation loss: \", val_loss)\n",
        "    \n",
        "# Save the model for future evaluation  \n",
        "torch.save(model, './mel_cnn')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:12:58.971520Z",
          "iopub.execute_input": "2022-02-27T13:12:58.971840Z",
          "iopub.status.idle": "2022-02-27T13:15:43.444886Z",
          "shell.execute_reply.started": "2022-02-27T13:12:58.971799Z",
          "shell.execute_reply": "2022-02-27T13:15:43.444103Z"
        },
        "trusted": true,
        "id": "dxT-UXpkqn6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./mel_cnn')\n",
        "model.eval()\n",
        "_, (y_test_gold, y_test_pred) = eval_dataset(test_loader_mel, model, loss_function)\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(classification_report(y_test_true, y_test_pred))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:15:43.446302Z",
          "iopub.execute_input": "2022-02-27T13:15:43.446581Z",
          "iopub.status.idle": "2022-02-27T13:15:43.462150Z",
          "shell.execute_reply.started": "2022-02-27T13:15:43.446545Z",
          "shell.execute_reply": "2022-02-27T13:15:43.461530Z"
        },
        "trusted": true,
        "id": "AqPSQpBYqn6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Βήμα 8"
      ],
      "metadata": {
        "id": "aIKuxL2Hqn6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultitaskDataset(Dataset):\n",
        "    def __init__(self, path, max_length=-1, read_spec_fn=read_fused_spectrogram, label_type='energy'):\n",
        "        p = os.path.join(path, 'train')\n",
        "        self.label_type = label_type\n",
        "        self.index = os.path.join(path, \"train_labels.txt\")\n",
        "        self.files, labels = self.get_files_labels(self.index)\n",
        "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
        "        self.feat_dim = self.feats[0].shape[1]\n",
        "        self.lengths = [len(i) for i in self.feats]\n",
        "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
        "        self.zero_pad_and_stack = PaddingTransform(self.max_length) \n",
        "        if isinstance(labels, (list, tuple)):\n",
        "            self.labels = np.array(labels)\n",
        "\n",
        "    def get_files_labels(self, txt):\n",
        "        with open(txt, 'r') as fd:\n",
        "            lines = [l.split(',') for l in fd.readlines()[1:]]\n",
        "        files, labels = [], []\n",
        "        for l in lines:\n",
        "            if self.label_type == 'valence':\n",
        "                labels.append(float(l[1]))\n",
        "            elif self.label_type == 'energy':\n",
        "                labels.append(float(l[2]))\n",
        "            elif self.label_type == 'danceability':\n",
        "                labels.append(float(l[3].strip(\"\\n\")))\n",
        "            else:\n",
        "                labels.append([float(l[1]), float(l[2]), float(l[3].strip(\"\\n\"))])\n",
        "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
        "            _id = l[0]\n",
        "            npy_file = '{}.fused.full.npy'.format(_id)\n",
        "            files.append(npy_file)\n",
        "        return files, labels\n",
        "    \n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # Return a tuple in the form (padded_feats, valence, energy, danceability, length)\n",
        "        l = min(self.lengths[item], self.max_length)\n",
        "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:27:26.217486Z",
          "iopub.execute_input": "2022-02-27T14:27:26.217742Z",
          "iopub.status.idle": "2022-02-27T14:27:26.231619Z",
          "shell.execute_reply.started": "2022-02-27T14:27:26.217714Z",
          "shell.execute_reply": "2022-02-27T14:27:26.230987Z"
        },
        "trusted": true,
        "id": "23UyrsJcqn6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specs_multi_valence = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
        "         max_length=1293,\n",
        "         label_type='valence',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "train_loader_valence , val_loader_valence = torch_train_val_split(specs_multi_valence, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:22:32.144634Z",
          "iopub.execute_input": "2022-02-27T13:22:32.145155Z",
          "iopub.status.idle": "2022-02-27T13:22:51.864823Z",
          "shell.execute_reply.started": "2022-02-27T13:22:32.145116Z",
          "shell.execute_reply": "2022-02-27T13:22:51.864070Z"
        },
        "trusted": true,
        "id": "ASBsJsQfqn6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specs_multi_energy = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
        "         max_length=1293,\n",
        "         label_type='energy',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "train_loader_energy, val_loader_energy = torch_train_val_split(specs_multi_energy, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:26:45.080211Z",
          "iopub.execute_input": "2022-02-27T13:26:45.080493Z",
          "iopub.status.idle": "2022-02-27T13:26:47.404452Z",
          "shell.execute_reply.started": "2022-02-27T13:26:45.080460Z",
          "shell.execute_reply": "2022-02-27T13:26:47.403634Z"
        },
        "trusted": true,
        "id": "sa-ORGYiqn6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specs_multi_danceability = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
        "         max_length=1293,\n",
        "         label_type='danceability',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "train_loader_danceability, val_loader_danceability = torch_train_val_split(specs_multi_danceability, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:26:54.133883Z",
          "iopub.execute_input": "2022-02-27T13:26:54.134135Z",
          "iopub.status.idle": "2022-02-27T13:26:56.760742Z",
          "shell.execute_reply.started": "2022-02-27T13:26:54.134107Z",
          "shell.execute_reply": "2022-02-27T13:26:56.760017Z"
        },
        "trusted": true,
        "id": "rP4ybhmWqn6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beat mulstitask dataset**\n"
      ],
      "metadata": {
        "id": "uah76AgGqn6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beat_specs_multi_valence = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',\n",
        "         max_length=-1,\n",
        "         label_type='valence',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "beat_train_loader_valence , beat_val_loader_valence = torch_train_val_split(beat_specs_multi_valence, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "trusted": true,
        "id": "i1cHYGaTqn6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat_specs_multi_energy = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',\n",
        "         max_length=-1,\n",
        "         label_type='energy',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "beat_train_loader_energy, beat_val_loader_energy = torch_train_val_split(beat_specs_multi_energy, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:25:46.464823Z",
          "iopub.execute_input": "2022-02-27T13:25:46.465079Z",
          "iopub.status.idle": "2022-02-27T13:25:52.943293Z",
          "shell.execute_reply.started": "2022-02-27T13:25:46.465051Z",
          "shell.execute_reply": "2022-02-27T13:25:52.942593Z"
        },
        "trusted": true,
        "id": "TSeyI3aUqn6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat_specs_multi_danceability = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',\n",
        "         max_length=-1,\n",
        "         label_type='danceability',\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "beat_train_loader_danceability, beat_val_loader_danceability = torch_train_val_split(beat_specs_multi_danceability, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:25:53.960984Z",
          "iopub.execute_input": "2022-02-27T13:25:53.961663Z",
          "iopub.status.idle": "2022-02-27T13:25:54.936026Z",
          "shell.execute_reply.started": "2022-02-27T13:25:53.961622Z",
          "shell.execute_reply": "2022-02-27T13:25:54.935338Z"
        },
        "trusted": true,
        "id": "GR_wxGllqn6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False, dropout=0):\n",
        "        super(BasicLSTM, self).__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.rnn_size = rnn_size\n",
        "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        # Initialize the LSTM, Dropout, Output layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, self.rnn_size, self.num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=self.dropout)\n",
        "        self.linear = nn.Linear(self.feature_size, output_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        \"\"\" \n",
        "            x : 3D numpy array of dimension N x L x D\n",
        "                N: batch index\n",
        "                L: sequence index\n",
        "                D: feature index\n",
        "\n",
        "            lengths: N x 1\n",
        "         \"\"\"\n",
        "        \n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        if self.bidirectional:\n",
        "            h0 = torch.zeros(self.num_layers*2, x.size(0), self.rnn_size).double().to(device)\n",
        "            c0 = torch.zeros(self.num_layers*2, x.size(0), self.rnn_size).double().to(device)\n",
        "        else:\n",
        "            h0 = torch.zeros(self.num_layers, x.size(0), self.rnn_size).double().to(device)\n",
        "            c0 = torch.zeros(self.num_layers, x.size(0), self.rnn_size).double().to(device)\n",
        "            \n",
        "        # Forward \n",
        "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
        "        last_outputs = self.linear(self.last_timestep(lstm_out, lengths, self.bidirectional))\n",
        "        return last_outputs.view(-1)\n",
        "\n",
        "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
        "        \"\"\"\n",
        "            Returns the last output of the LSTM taking into account the zero padding\n",
        "        \"\"\"\n",
        "        if bidirectional:\n",
        "            forward, backward = self.split_directions(outputs)\n",
        "            last_forward = self.last_by_index(forward, lengths)\n",
        "            last_backward = backward[:, 0, :]\n",
        "            return torch.cat((last_forward, last_backward), dim=-1)\n",
        "\n",
        "        else:\n",
        "            return self.last_by_index(outputs, lengths)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_directions(outputs):\n",
        "        direction_size = int(outputs.size(-1) / 2)\n",
        "        forward = outputs[:, :, :direction_size]\n",
        "        backward = outputs[:, :, direction_size:]\n",
        "        return forward, backward\n",
        "\n",
        "    @staticmethod\n",
        "    def last_by_index(outputs, lengths):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
        "                                               outputs.size(2)).unsqueeze(1).to(device)\n",
        "        return outputs.gather(1, idx).squeeze()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mGJbEYkDqn6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataset_regression(_epoch, dataloader, model, loss_function, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    for index, batch in enumerate(dataloader, 1):\n",
        "        inputs, labels, lengths = batch\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "            \n",
        "    \n",
        "        # clear gradients out before each batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forward pass\n",
        "        y_preds = model(inputs, lengths)\n",
        "        loss = loss_function(y_preds, labels.double())\n",
        "\n",
        "        #backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.data.item()\n",
        "\n",
        "    return running_loss / index"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:22:03.255442Z",
          "iopub.execute_input": "2022-02-27T13:22:03.255908Z",
          "iopub.status.idle": "2022-02-27T13:22:03.262838Z",
          "shell.execute_reply.started": "2022-02-27T13:22:03.255870Z",
          "shell.execute_reply": "2022-02-27T13:22:03.262186Z"
        },
        "trusted": true,
        "id": "gqznwNSdqn6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_dataset_regression(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    y_pred = []  \n",
        "    y = []  \n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(dataloader, 1):\n",
        "            inputs, labels, lengths = batch\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            #forward pass\n",
        "            y_preds = model(inputs, lengths)\n",
        "\n",
        "            #compute loss\n",
        "            loss = loss_function(y_preds, labels.double())\n",
        "\n",
        "            y_pred.append(y_preds.cpu().numpy())\n",
        "            y.append(labels.cpu().numpy())\n",
        "\n",
        "            running_loss += loss.data.item()\n",
        "\n",
        "    return running_loss / index, (y, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:23:26.539131Z",
          "iopub.execute_input": "2022-02-27T13:23:26.539387Z",
          "iopub.status.idle": "2022-02-27T13:23:26.547442Z",
          "shell.execute_reply.started": "2022-02-27T13:23:26.539358Z",
          "shell.execute_reply": "2022-02-27T13:23:26.546459Z"
        },
        "trusted": true,
        "id": "gSkYgvPMqn6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Valence with LSTM**"
      ],
      "metadata": {
        "id": "G3wYmgToqn6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "model = BasicLSTM(num_mel, RNN_SIZE, 1, 1, bidirectional=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, beat_train_loader_valence, model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, _ = eval_dataset_regression(beat_train_loader_valence, model, loss_function)\n",
        "\n",
        "    val_loss, _ = eval_dataset_regression(beat_val_loader_valence, model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch \", epoch)\n",
        "        print(\"Train loss: \", train_loss)\n",
        "        print(\"Validation loss: \", val_loss)\n",
        "        \n",
        "torch.save(model, './multitask_lstm_valence')"
      ],
      "metadata": {
        "trusted": true,
        "id": "x-FM_QoNqn6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_lstm_valence')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(beat_val_loader_valence, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "_A2edNwdqn6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Energy with LSTM**"
      ],
      "metadata": {
        "id": "kU44fJ4Cqn6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "model = BasicLSTM(num_mel, RNN_SIZE, 1, 1, bidirectional=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train the model for one epoch\n",
        "    train_dataset_regression(epoch, beat_train_loader_energy, model, loss_function, optimizer)\n",
        "    \n",
        "    # Evaluate the performance of the model, on both data sets\n",
        "    train_loss, _ = eval_dataset_regression(beat_train_loader_energy, model, loss_function)\n",
        "\n",
        "    val_loss, _ = eval_dataset_regression(beat_val_loader_energy, model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        \n",
        "torch.save(model, './multitask_lstm_energy')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ijeGh3GWqn6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_lstm_energy')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(beat_val_loader_energy, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: %f\" %spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "qCUcd-Adqn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Danceability with LSTM**"
      ],
      "metadata": {
        "id": "10mLNiBwqn6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "model = BasicLSTM(num_mel, RNN_SIZE, 1, 1, bidirectional=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, beat_train_loader_danceability, model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, _ = eval_dataset_regression(beat_train_loader_danceability, model, loss_function)\n",
        "\n",
        "    val_loss, _ = eval_dataset_regression(beat_val_loader_danceability, model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        \n",
        "torch.save(model, './multitask_lstm_danceability')"
      ],
      "metadata": {
        "trusted": true,
        "id": "MaHTw9PTqn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_lstm_danceability')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(beat_val_loader_danceability, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "CRj38_5Aqn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN with regression\n",
        "\n",
        "class ConvNetMultitask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetMultitask, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
        "        self.conv1_bn = nn.BatchNorm2d(3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2_bn = nn.BatchNorm2d(6)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(6, 8, 3)\n",
        "        self.conv3_bn = nn.BatchNorm2d(8)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(8, 12, 3)\n",
        "        self.conv4_bn = nn.BatchNorm2d(12)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "                \n",
        "        self.fc1 = nn.Linear(4680, 128)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x.view(x.size(0), 1, x.size(1), x.size(2))\n",
        "        \n",
        "        x = self.pool1(F.relu( self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool2(F.relu( self.conv2_bn(self.conv2(x))))\n",
        "        x = self.pool3(F.relu( self.conv3_bn(self.conv3(x))))\n",
        "        x = self.pool4(F.relu( self.conv4_bn(self.conv4(x))))\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:20:58.249143Z",
          "iopub.execute_input": "2022-02-27T13:20:58.249395Z",
          "iopub.status.idle": "2022-02-27T13:20:58.260434Z",
          "shell.execute_reply.started": "2022-02-27T13:20:58.249366Z",
          "shell.execute_reply": "2022-02-27T13:20:58.259762Z"
        },
        "trusted": true,
        "id": "pf_RmHowqn6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Valence with CNN**"
      ],
      "metadata": {
        "id": "K_bjFloOqn6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model = ConvNetMultitask()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train the model for one epoch\n",
        "    train_dataset_regression(epoch, train_loader_valence, model, loss_function, optimizer)\n",
        "    \n",
        "    # Evaluate the performance of the model, on both data sets\n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_valence, model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_valence, model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: %f\" %spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: %f\" %spearmanr(y_val_true, y_val_pred)[0])\n",
        "        print()\n",
        "        \n",
        "torch.save(model, './multitask_cnn_valence')"
      ],
      "metadata": {
        "trusted": true,
        "id": "tzb6f37Vqn6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_cnn_valence')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_valence, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "0sMSt6Jtqn6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Energy with CNN**"
      ],
      "metadata": {
        "id": "yWQcguK5qn6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model = ConvNetMultitask()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, train_loader_energy, model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_energy, model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_energy, model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: %f\" %spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: %f\" %spearmanr(y_val_true, y_val_pred)[0])\n",
        "        print()\n",
        "        \n",
        "torch.save(model, './multitask_cnn_energy')"
      ],
      "metadata": {
        "trusted": true,
        "id": "YAg8l6NNqn6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_cnn_energy')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_energy, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])\n",
        "print()"
      ],
      "metadata": {
        "trusted": true,
        "id": "P038h9mSqn6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Danceability with CNN**"
      ],
      "metadata": {
        "id": "a-gKFW4gqn6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model = ConvNetMultitask()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, train_loader_danceability, model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_danceability, model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_danceability, model, loss_function)\n",
        "    \n",
        "    if epoch 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: %f\" %spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: \", spearmanr(y_val_true, y_val_pred)[0])\n",
        "        \n",
        "torch.save(model, './multitask_cnn_danceability')"
      ],
      "metadata": {
        "trusted": true,
        "id": "e_zEwvb2qn6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_cnn_danceability')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_danceability, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "wjfHiyyGqn6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Βήμα 9"
      ],
      "metadata": {
        "id": "SRkvKn4Uqn6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#κάνουμε load το μοντέλο του βήματος 7\n",
        "transfer_model = torch.load('./mel_cnn')\n",
        "print(transfer_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:21:13.412912Z",
          "iopub.execute_input": "2022-02-27T13:21:13.413166Z",
          "iopub.status.idle": "2022-02-27T13:21:13.428453Z",
          "shell.execute_reply.started": "2022-02-27T13:21:13.413138Z",
          "shell.execute_reply": "2022-02-27T13:21:13.427709Z"
        },
        "trusted": true,
        "id": "QR5njk9bqn6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Οι παράμετροι του αρχικού μοντέλου δεν θα ξανααλλάξουν\n",
        "for param in transfer_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:21:19.598390Z",
          "iopub.execute_input": "2022-02-27T13:21:19.599025Z",
          "iopub.status.idle": "2022-02-27T13:21:19.604688Z",
          "shell.execute_reply.started": "2022-02-27T13:21:19.598988Z",
          "shell.execute_reply": "2022-02-27T13:21:19.602014Z"
        },
        "trusted": true,
        "id": "XJKzXlfEqn6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Αλλάζουμε το τελευταίο layer για να ταιριάξει με το νέο δίκτυο\n",
        "transfer_model.fc2 = nn.Linear(128, 1)\n",
        "print(transfer_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:21:27.219162Z",
          "iopub.execute_input": "2022-02-27T13:21:27.219701Z",
          "iopub.status.idle": "2022-02-27T13:21:27.225619Z",
          "shell.execute_reply.started": "2022-02-27T13:21:27.219662Z",
          "shell.execute_reply": "2022-02-27T13:21:27.224871Z"
        },
        "trusted": true,
        "id": "YIm5kr43qn60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Εκπαιδεύεται το τελευταίο layer\n",
        "EPOCHS = 20\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfer_model.double()\n",
        "transfer_model.to(DEVICE)\n",
        "loss_function = nn.MSELoss().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train the model for one epoch\n",
        "    train_dataset_regression(epoch, train_loader_valence, transfer_model, loss_function, optimizer)\n",
        "    \n",
        "    # Evaluate the performance of the model, on both data sets\n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_valence, transfer_model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_valence, transfer_model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: %f\" %spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: %f\" %spearmanr(y_val_true, y_val_pred)[0])\n",
        "\n",
        "        \n",
        "torch.save(transfer_model, './multitask_transfer_valence')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:23:38.492203Z",
          "iopub.execute_input": "2022-02-27T13:23:38.492871Z",
          "iopub.status.idle": "2022-02-27T13:25:05.271159Z",
          "shell.execute_reply.started": "2022-02-27T13:23:38.492829Z",
          "shell.execute_reply": "2022-02-27T13:25:05.269615Z"
        },
        "trusted": true,
        "id": "D3DxYwX3qn60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = torch.load('./multitask_transfer_valence')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_valence, transfer_model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: %f\" %spearmanr(y_test_true, y_test_pred)[0])\n",
        "print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:25:05.273150Z",
          "iopub.execute_input": "2022-02-27T13:25:05.273414Z",
          "iopub.status.idle": "2022-02-27T13:25:06.076110Z",
          "shell.execute_reply.started": "2022-02-27T13:25:05.273380Z",
          "shell.execute_reply": "2022-02-27T13:25:06.075362Z"
        },
        "trusted": true,
        "id": "hBwbTXiOqn60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = torch.load('./mel_cnn')\n",
        "\n",
        "for param in transfer_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "transfer_model.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfer_model.double()\n",
        "transfer_model.to(DEVICE)\n",
        "loss_function = nn.MSELoss().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, train_loader_energy, transfer_model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_energy, transfer_model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_energy, transfer_model, loss_function)\n",
        "    \n",
        "    if epoch % 5 == 0: \n",
        "        print(\"Epoch \", epoch)\n",
        "        print(\"Train loss: \", train_loss)\n",
        "        print(\"Validation loss: \", val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: \", spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: \", spearmanr(y_val_true, y_val_pred)[0])\n",
        "\n",
        "        \n",
        "torch.save(transfer_model, './multitask_transfer_energy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:27:07.575513Z",
          "iopub.execute_input": "2022-02-27T13:27:07.576016Z",
          "iopub.status.idle": "2022-02-27T13:28:34.974292Z",
          "shell.execute_reply.started": "2022-02-27T13:27:07.575971Z",
          "shell.execute_reply": "2022-02-27T13:28:34.973582Z"
        },
        "trusted": true,
        "id": "zf2GSOuwqn60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = torch.load('./multitask_transfer_energy')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_energy, transfer_model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:28:34.975979Z",
          "iopub.execute_input": "2022-02-27T13:28:34.977619Z",
          "iopub.status.idle": "2022-02-27T13:28:35.772925Z",
          "shell.execute_reply.started": "2022-02-27T13:28:34.977579Z",
          "shell.execute_reply": "2022-02-27T13:28:35.772146Z"
        },
        "trusted": true,
        "id": "kKlf4ZGiqn61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = torch.load('./mel_cnn')\n",
        "\n",
        "for param in transfer_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "transfer_model.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfer_model.double()\n",
        "transfer_model.to(DEVICE)\n",
        "loss_function = nn.MSELoss().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression(epoch, train_loader_danceability, transfer_model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression(train_loader_danceability, transfer_model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression(val_loader_danceability, transfer_model, loss_function)\n",
        "    \n",
        "    if epoch%(1) == 0: \n",
        "        print(\"Epoch %d \" %epoch)\n",
        "        print(\"Train loss: %f\" %train_loss)\n",
        "        print(\"Validation loss: %f\" %val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "        print(\"Spearman in train: %f\" %spearmanr(y_train_true, y_train_pred)[0])\n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation: %f\" %spearmanr(y_val_true, y_val_pred)[0])\n",
        "\n",
        "        \n",
        "torch.save(transfer_model, './multitask_transfer_danceability')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:28:35.774111Z",
          "iopub.execute_input": "2022-02-27T13:28:35.774422Z",
          "iopub.status.idle": "2022-02-27T13:30:03.160054Z",
          "shell.execute_reply.started": "2022-02-27T13:28:35.774366Z",
          "shell.execute_reply": "2022-02-27T13:30:03.159326Z"
        },
        "trusted": true,
        "id": "5fQ4zkFyqn61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = torch.load('./multitask_transfer_danceability')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression(val_loader_danceability, transfer_model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "print(\"Spearman: \", spearmanr(y_test_true, y_test_pred)[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T13:30:03.161886Z",
          "iopub.execute_input": "2022-02-27T13:30:03.162282Z",
          "iopub.status.idle": "2022-02-27T13:30:03.960398Z",
          "shell.execute_reply.started": "2022-02-27T13:30:03.162245Z",
          "shell.execute_reply": "2022-02-27T13:30:03.959606Z"
        },
        "trusted": true,
        "id": "0tRUnqxyqn61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Βήμα 10"
      ],
      "metadata": {
        "id": "F3U8Xtojqn62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specs_multi_all = MultitaskDataset(\n",
        "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
        "         max_length=1293,\n",
        "         label_type=-1,\n",
        "         read_spec_fn=read_mel_spectrogram)\n",
        "\n",
        "train_loader_all, val_loader_all = torch_train_val_split(specs_multi_all, 32 ,32, val_size=.33)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:34:43.070565Z",
          "iopub.execute_input": "2022-02-27T14:34:43.070885Z",
          "iopub.status.idle": "2022-02-27T14:34:45.603317Z",
          "shell.execute_reply.started": "2022-02-27T14:34:43.070843Z",
          "shell.execute_reply": "2022-02-27T14:34:45.602541Z"
        },
        "trusted": true,
        "id": "UAK9NquNqn62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataset_regression_multi(_epoch, dataloader, model, loss_function, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    for index, batch in enumerate(dataloader, 1):\n",
        "        inputs, labels, lengths = batch\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        y_preds_val, y_preds_energy, y_preds_dance = model(inputs, lengths)\n",
        "        \n",
        "        # Loss\n",
        "        loss_1 = loss_function(y_preds_val, labels[:, 0].double())\n",
        "        loss_2 = loss_function(y_preds_energy, labels[:, 1].double())\n",
        "        loss_3 = loss_function(y_preds_dance, labels[:, 2].double())\n",
        "        loss = loss_1 + loss_2 + loss_3\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.data.item()\n",
        "\n",
        "    return running_loss / index"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:34:45.616660Z",
          "iopub.execute_input": "2022-02-27T14:34:45.616960Z",
          "iopub.status.idle": "2022-02-27T14:34:45.626405Z",
          "shell.execute_reply.started": "2022-02-27T14:34:45.616923Z",
          "shell.execute_reply": "2022-02-27T14:34:45.625696Z"
        },
        "trusted": true,
        "id": "KboP_TOZqn63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_dataset_regression_multi(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    y_pred = []\n",
        "    y = []\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(dataloader, 1):\n",
        "            inputs, labels, lengths = batch\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            #Forward pass\n",
        "            y_preds_val, y_preds_energy, y_preds_dance = model(inputs, lengths)\n",
        "\n",
        "            # Loss = άθροισμα όλων\n",
        "            loss_1 = loss_function(y_preds_val, labels[:, 0].double())\n",
        "            loss_2 = loss_function(y_preds_energy, labels[:, 1].double())\n",
        "            loss_3 = loss_function(y_preds_dance, labels[:, 2].double())\n",
        "            loss = loss_1 + loss_2 + loss_3\n",
        "        \n",
        "            y_pred.append(np.hstack((y_preds_val.cpu().numpy(), y_preds_energy.cpu().numpy(), y_preds_dance.cpu().numpy())))\n",
        "            y.append(labels.cpu().numpy())\n",
        "\n",
        "            running_loss += loss.data.item()\n",
        "    return running_loss / index, (y, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:34:45.628294Z",
          "iopub.execute_input": "2022-02-27T14:34:45.628817Z",
          "iopub.status.idle": "2022-02-27T14:34:45.640407Z",
          "shell.execute_reply.started": "2022-02-27T14:34:45.628756Z",
          "shell.execute_reply": "2022-02-27T14:34:45.639516Z"
        },
        "trusted": true,
        "id": "Xcfvs3mGqn63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNetMultitaskLearning(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetMultitaskLearning, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
        "        self.conv1_bn = nn.BatchNorm2d(3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2_bn = nn.BatchNorm2d(6)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(6, 8, 3)\n",
        "        self.conv3_bn = nn.BatchNorm2d(8)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(8, 12, 3)\n",
        "        self.conv4_bn = nn.BatchNorm2d(12)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(12, 16, 3)\n",
        "        self.conv5_bn = nn.BatchNorm2d(16)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)\n",
        "                \n",
        "        self.fc1 = nn.Linear(1216, 32)\n",
        "        \n",
        "        self.fc_val = nn.Linear(32, 1)\n",
        "        \n",
        "        self.fc_energy = nn.Linear(32, 1)\n",
        "        \n",
        "        self.fc_dance = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x.view(x.size(0), 1, x.size(1), x.size(2))\n",
        "        \n",
        "        x = self.pool1(F.relu( self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool2(F.relu( self.conv2_bn(self.conv2(x))))\n",
        "        x = self.pool3(F.relu( self.conv3_bn(self.conv3(x))))\n",
        "        x = self.pool4(F.relu( self.conv4_bn(self.conv4(x))))\n",
        "        x = self.pool5(F.relu( self.conv5_bn(self.conv5(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        energy = self.fc_energy(x)\n",
        "        \n",
        "        val = self.fc_val(x)\n",
        "        \n",
        "        dance = self.fc_dance(x)\n",
        "        \n",
        "        return val, energy, dance"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:34:45.641694Z",
          "iopub.execute_input": "2022-02-27T14:34:45.642131Z",
          "iopub.status.idle": "2022-02-27T14:34:45.659044Z",
          "shell.execute_reply.started": "2022-02-27T14:34:45.642076Z",
          "shell.execute_reply": "2022-02-27T14:34:45.657840Z"
        },
        "trusted": true,
        "id": "7bcVapfrqn63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model = ConvNetMultitaskLearning()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.double()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "n_epochs_stop = 10\n",
        "min_val_loss = 1000\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset_regression_multi(epoch, train_loader_all, model, loss_function, optimizer)\n",
        "    \n",
        "    train_loss, (y_train, y_train_pred) = eval_dataset_regression_multi(train_loader_all, model, loss_function)\n",
        "\n",
        "    val_loss, (y_val, y_val_pred) = eval_dataset_regression_multi(val_loader_all, model, loss_function)\n",
        "    \n",
        "    if val_loss < min_val_loss:\n",
        "        torch.save(model, './multitask_learning')\n",
        "        epochs_no_improve = 0\n",
        "        min_val_loss = val_loss\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "            \n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "        print('Early stopping!')\n",
        "        break\n",
        "    if epoch%(1) == 0: \n",
        "        print(\"Epoch \", epoch)\n",
        "        print(\"Train loss: \", train_loss)\n",
        "        print(\"Validation loss: \", val_loss)\n",
        "        y_train_true = np.concatenate( y_train, axis=0 )\n",
        "        y_train_pred = np.concatenate( y_train_pred, axis=0 )\n",
        "\n",
        "        print(\"Spearman in train - valence: \", spearmanr(y_train_true[:,0], y_train_pred[:,0])[0])\n",
        "        print(\"Spearman in train - energy: \", spearmanr(y_train_true[:,1], y_train_pred[:,1])[0])\n",
        "        print(\"Spearman in train - dance: \", spearmanr(y_train_true[:,2], y_train_pred[:,2])[0])\n",
        "        \n",
        "        y_val_true = np.concatenate( y_val, axis=0 )\n",
        "        y_val_pred = np.concatenate( y_val_pred, axis=0 )\n",
        "        print(\"Spearman in validation - valence: \", spearmanr(y_val_true[:,0], y_val_pred[:,0])[0])\n",
        "        print(\"Spearman in validation - energy: \", spearmanr(y_val_true[:,1], y_val_pred[:,1])[0])\n",
        "        print(\"Spearman in validation - dance: \", spearmanr(y_val_true[:,2], y_val_pred[:,2])[0])\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:39:40.993591Z",
          "iopub.execute_input": "2022-02-27T14:39:40.994118Z",
          "iopub.status.idle": "2022-02-27T14:43:37.101235Z",
          "shell.execute_reply.started": "2022-02-27T14:39:40.994080Z",
          "shell.execute_reply": "2022-02-27T14:43:37.100173Z"
        },
        "trusted": true,
        "id": "hLrtwgnqqn64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./multitask_learning')\n",
        "\n",
        "test_loss, (y_test_gold, y_test_pred) = eval_dataset_regression_multi(val_loader_all, model, loss_function)\n",
        "\n",
        "y_test_true = np.concatenate( y_test_gold, axis=0 )\n",
        "y_test_pred = np.concatenate( y_test_pred, axis=0 )\n",
        "\n",
        "print(y_test_true.shape)\n",
        "\n",
        "print(\"Spearman: \", spearmanr(y_test_true[:,0], y_test_pred[:,0])[0])\n",
        "print(\"Spearman: \", spearmanr(y_test_true[:,1], y_test_pred[:,1])[0])\n",
        "print(\"Spearman: \", spearmanr(y_test_true[:,2], y_test_pred[:,2])[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T14:43:37.103293Z",
          "iopub.execute_input": "2022-02-27T14:43:37.103688Z",
          "iopub.status.idle": "2022-02-27T14:43:37.744808Z",
          "shell.execute_reply.started": "2022-02-27T14:43:37.103639Z",
          "shell.execute_reply": "2022-02-27T14:43:37.744017Z"
        },
        "trusted": true,
        "id": "O3QeA5zYqn64"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}